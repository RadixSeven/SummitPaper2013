\documentclass[eric_thesis.tex]{subfiles}
\begin{document}
\chapter{Factor Interpretation}

As I performed the component extractions, I examined the sorted word-lists, 
which meant that I saw them in approximate numerical order according to the size 
of the list. As I examined the components for the smaller word lists, I had 
trouble coming up with coherent explanations. Some of the first few components 
seemed related to a good/bad trait listing but the rest of the components will 
be difficult to figure out. For example, components 1 and 2 of the unnormalized 
101 word set seem to be more-or-less good/bad. This is a rough characterization. 
Component 1 includes both extroverted and bashful on the ``bad'' side and 
component 2 includes prompt on its bad side. But the rest of the components are 
hard to describe. Even in the smaller lists, the MDS transform makes them much 
more interpretable. In the first two components, there are many fewer strange 
entries at the ends than when using the other two normalization methods. The 
rest of the components are still hard to interpret though this is more from a 
lack of vocabulary than from no sense in the ordering. In hindsight, having seen 
the larger MDS set, it is clear that the third component is sorted on formality 
and the fourth is related to how often the word is used to describe nonhuman 
versus human characteristics. Based on Figure 
\ref{fig:100vs2797First22} I believe that dimensions 6, 7, 8, 9 and 11
would also be interpretable in hindsight.

Factor interpretation is very time consuming so I was unable to look at all of 
the word-list/transformation combinations however, I made an attempt to 
interpret the factors arising out of some of the larger lists.

\section{2797 Word with MDS}

Once I reached the 2797 word list based on \citep{Norman1967}, interpretation 
became much easier. I think more than 14 components might be interpretable, 
however, I only had time for 14. Several of those need some improvement. 
My interpretations are in Table
\ref{tab:2797mdsinterp}.

\subsection{Component 1}

The first dimension needs a bit of explanation. In the corpus, the 10 highest 
ranked words appear in 526,515/117,296,559 sentences (0.4\%), the 10 lowest 
ranked words appear in only 5,871 (0.005\%). This is even more pronounced in the 
minutes of the European parliament where the highly ranked words appear in 
19,196/2,015,440 sentences (1\%) but the lowest ranked words appear in 14 
(0.0006\%) (And, in all of those sentences, the only word appearing is 
sly\_jj - the highest ranked word among the lowest 10). Thus, it may not be 
just that these words are more common, but that they are more common in 
political speech.

I looked at the Spearman correlation between number of occurrences of the words 
in the entire corpus and the values on the first dimension. It was 0.5739 
(which gives a $p$ value of $1.9120 \times 10^{-163}$ against the null hypothesis 
that there is no relationship). There is no other component which is so 
strongly correlated with word frequency. However, the correlation is not 
perfect. For example, the most frequent word in the list has a rank of 204 when 
you look at its score on the first dimension.

To investigate the hypothesis that these words are not just more common but 
more common in political speech, I also looked at the correlation with 
frequency in the European parliament records. The correlation between this 
component and parliamentary frequency is 0.6881 
($p=3.8268 \times 10^{-261}$).  It rises even farther to 0.7027 when looking 
at only words that appear in the 
parliamentary records. That it is not a perfect correlation indicates that 
there are still things I am overlooking. However, describing this dimension as 
``uncommon in parliament vs common'' seems to have some explanatory power.

\begin{table}[tbp]
\begin{tabular}{ | l |p{2in}|p{2in}|}
 \hline
 C & Low & High \\
 \hline
 1 & Uncommon in parliament & Common in parliament\\
 2 & Negative & Positive\\
 3 & Mainly describes humans & Describes non-humans also \\
 4 & Informal & Formal \\
 5 & Used in conflict & Used in peace \\
 6 & Unrelated to patriotism or authority-group loyalty & Related to 
     patriotism or authority-group loyalty \\
 7 & Stereotypical rebellious intellectual & Stereotypical opponent of 
     rebellious intellectual \\
 8 & Less emotional words & Emotionally charged words \\
 9 & Social / ostentation & Private  \\
 10 & Business context & Religion / family / clan context \\
 11 & Qualities relevant to violent situations & Qualities relevant to 
       non-violent situations \\
 12 & Unsettled exploration & Restaurant and food \\
 13 & Travel words & Interview words \\
 14 & Words that can describe both food and politicians &  Unknown \\
 \hline
\end{tabular}
 \caption{Interpretations of the different components identified from the 2797
 word list after MDS}
 \label{tab:2797mdsinterp}
\end{table}

\section{All combined with MDS}

When I combine all the word lists and apply MDS, the factors look similar to 
the 2797 word list by itself. See Table \ref{tab:2797and438and101mdsinterp}. 
There is a bit of variation in factors 5, 6, and 9 but not enough to really 
change the interpretation that much.

\begin{table}[tbp]
\begin{tabular}{ | l |p{2in}|p{2in}|}
 \hline
 C & Low & High \\
 \hline
 1* & Uncommon in parliament & Common in parliament\\
 2* & Negative & Positive\\
 3* & Mainly describes humans & Describes non-humans also \\
 4* & Informal & Formal \\
 5* & Used in peace & Used in conflict \\
 6 & Unrelated to group devotion & Group devotion \\
 7* & Stereotypical rebellious intellectual & Stereotypical opponent of 
     rebellious intellectual \\
 8* & Less emotional words & Emotionally charged words \\
 9* & Social / ostentation & Private  \\
 \hline
\end{tabular}
 \caption{Interpretations of the different components identified from the combining
 all three word lists after MDS. * means the same as the 2797 interpretation.}
 \label{tab:2797and438and101mdsinterp}
\end{table}


\section{2797 with z-score}

The z-score normalized factors, even in the 2797 word list were much harder to 
interpret than the MDS normalized ones. There are also more exceptions to each 
rule. This is to be expected from the difference between the dot-product 
space in which the similarity actually is measured and the euclidean space in 
which the z-score and PCA combination operates. The rough interpretation of 
the first four factors is in Table \ref{tab:2797zscoreinterp}.

\begin{table}[tbp]
\begin{tabular}{ | l |p{2in}|p{2in}|}
 \hline
 C & Low & High \\
 \hline
 1 & Business & Fashion \\
 2 & Socially pleasant & Socially unpleasant \\
 3 & Leadership qualities & Words unrelated to leadership \\
 4 & Irrational commitment & Words that describe art \\
 \hline
\end{tabular}
 \caption{Interpretations of the different components identified from the 
 2797 word list after z-score normalization.}
 \label{tab:2797zscoreinterp}
\end{table}

\chapter{Discussion}

\section{Many ways to approach meaning}

In the first 14 components of the MDS basis for the 2797 word set, the word
``sly\_jj'' can be represented in percentiles as (2, 59, 59, 85, 20, 59, 41, 
53, 36, 81, 46, 25, 68, 40). With a range of 30-70\% for average, this means 
that sly as an adjective is very non-parliamentary, quite informal, useful in 
conflict, is seen more often when discussing matters of social allegiance than
economic, and is characteristic of unsettled exploration. Otherwise, sly is an
average word. It is hard to deny that these categories capture some 
understanding of the word sly and how it is used. However, this description of
the word sly is quite different from it's dictionary definitions: 
``clever in concealing one's aims or ends,'' ``lacking in straightforwardness 
and candor,'' and ``lightly mischievous.'' \citep{SlyMerriamWebster2014}

One could approach this result by saying that the computer is wrong, that the
algorithm has not captured the meaning of the word sly. But this is not very
attractive because using this same computer definition of the meaning of sly,
the computer can find other words which everyone would agree have similar 
meanings to sly and also find words in other languages that by general 
consensus have the same meaning as sly. To say that it can do this without
having captured at least the majority of the meaning of sly is a hard claim
to believe. 

Instead, I propose that the computer is working in an analogous semantic space
to humans, but it has divided it up differently. A simple version of this 
happens across different languages. A native Spanish speaker from Colombia calls 
many things
``verde'' that I, a native English speaker, call ``blue.'' ``verde'' is usually
glossed as ``green'' however, the Colombians divide up the color world slightly
differently, so that although ``verde'' is normally ``green,'' for some things
it is ``blue.'' Similarly, the process of training the \modelname{} model has
produced a division of the semantic space focusing on the characteristics of 
the words and their usage. Humans focus instead on the referents of the words.
In its training, the computer algorithm did not have access to the embodied
experiences that humans take for granted and could not take them into account
in its model. These would have to be additional latent variables of a different
type.

I see the computer's model in a similar way to the earlier example of PCA in 
Figure \ref{fig:pcarotation}. The principal components captured very important
characteristics of the data that was presented. And, provided information in 
the right 
form so accurate predictions could be made. However, because it was the wrong
type of model, it it couldn't capture the clumpiness of the data or the 
shape of those clumps. Thus it missed many important features of the space. In 
the same way
the \modelname{} model captures important features of the lexical semantic space
in a useful form. However, it is not a human brain and does not have the 
experiences that affect how a human responds to a given word. As such, it has
both the wrong model and incomplete input data. However, given those limitations
it does a remarkable job.

\section{Things captured by \modelname{}}

I think the first six dimensions of the MDS \modelname{} model captured
 interesting characteristics of personality language in the WMT11 dataset.
%
\begin{enumerate}
 \item Difference in usage for the parliamentary subset
 \item Negative/positive
 \item Human/general
 \item Fighting words
 \item Group loyalty
\end{enumerate}

\subsection{Parliamentary usage}

On the one hand, this dimension is an artifact of how the model was trained.
The parliamentary dataset was not mixed in with the other data but rather was
first. Since the model has its largest learning rate at the beginning, it moved
swiftly to represent parliamentary usage. Only words that did not appear often
in the parliamentary dataset escaped this initial movement. Because the 
parliamentary records are a small fraction of the entire dataset, if I had 
shuffled the entire dataset rather than just concatenating the files as they 
came I believe it would have had much less influence.

On the other hand, the presence of this artifact is another confirmation that
indeed the model is picking up the nuances of the text. It was able to pick up
the subtle differences in word sense between news writing and political speech.
This sort of sensitivity is exactly what makes it such a good tool for exploring
language and its usage.

It also implies that we might be able to get at usage differences by starting a
model with a small dataset whose characteristics we are interested in and then
continuing with a larger dataset. The differences between a dataset trained in
this way and one trained exclusively with the larger dataset would reflect 
differences in the usage between them while still taking advantage of the richer
semantic network available with the larger dataset. It would be interesting to
compare this procedure with those of: just training one model for each dataset
and training one model for the smaller dataset and one an equal-sized subset of
the larger dataset.

\subsection{Negative/Positive}

As was noted earlier, humans have a tendency to rate everything as negative and
positive \citep{Samsonovich2010}. Thus, its appearance in personality words
is not surprising. Studies have detected negative and positive factors
in Hebrew, Spanish, Filipino, and Greek \citep[p. 134]{DeRaad2009}. 

\subsection{Human/General}

The most interesting dimension to come out of the analysis is the third one.
It seems to measure the degree to which a word is specific to humans rather than
only being applied to them by analogy. 
If it indeed measures the degree of polysemy in personality words, we may be 
able to focus in on just the words that most matter to the study of personality
and look at their characteristics. Additionally, we may be able to 
semi-automatically produce a list of candidate words in an objective manner by
finding other words that are very human specific. This would help make up for
the original, human word lists' arbitrary exclusion of particular forms of 
different
personality words and help make up for the meaning shift that occurs in the 
natural evolution of language.

\subsection{Formality, Belligerence, and Group devotion}

The final three categories are all related to the social context of speech. In
American English, it is easy to recognize that many word forms exist to express
nuances of formality\footnote{To put it less formally: ``We change our
talk so we can be one of the guys.''}. Conflict and loyalty are also important
parts of our social lives, so it makes sense that they would be important in
our description of others.

\section{Superiority of MDS}

These important dimensions only were apparent in the MDS scaled vectors. I think
it is safe to say that in this case, the Euclidean distance metric was not a
good enough approximation to the cosine distance. Part of that may be because
we were not working with unit vectors. If one were to normalize all the vectors 
to unit length before doing the z-score transformation, it might make the 
dimensions obtained through standard PCA more usable.

\section{Where are the personality dimensions?}

Even with unit vectors, through, I believe that we will not find the Big Five or 
another major personality model in this data. First, those models come about 
because of the covariance structure of personality in single individuals; if an 
individual is trusting, he is more likely to be altruistic. In the WMT11 
dataset, there are descriptions of individuals, but they are all mashed up 
together. Using several adjectives to describe a single individual is not done 
very often. And when it is done, it is frequently done in different sentences 
(which will completely remove the connection due to sentence order 
randomization). Since most occurrences of the trait words are describing 
different individuals, there is no way for the algorithm to pick up on the 
commonalities. Second, a less certain reason: as was stated above, the model is 
looking more at the characteristics of the words rather than at what they refer 
to. I think that the personality models are more closely related to the referent 
than to the way in which it is described.

\section{Consistency across different word-sets}

Before doing this experiment, it would have been conceivable that

\section{Not what I expected}

\section{Could it be the corpus?}

WMT11 is a news corpus. Possibly its topic matter does not focus on people enough for those word senses to be properly represented. There are other, smaller, corpora with much broader language representation - for example, the brown corpus is a well known and freely available million word corpus. The British National Corpus is in the hundreds of millions of words and was created to be very broad-based. Additionally, there are spoken-language corpora like MICASE (Michigan Corpus of Academic Spoken English) and CPSA (Corpus of Spoken Professional American-English). These corpora could be used by themselves or potentially improved by using a model derived from a large news corpus like WMT11 or Gigaword as a starting point and then training on the smaller corpus.

\section{Could it be polysemy?}

\section{Could the dimensions be non-personality attributes?}
\section{Could the dimensions not be scaled on personality-ness?}

\todo{What I mean here is that the dimensions could be things like ``suitability to describe warmth'' both cold and warm would score highly but organized would score low.}

\section{Could the number of dimensions in the lexical model be affecting things?}

\section{Could the personality meanings not be being captured?}

\todo{This may be part of the previous - too few or too many dimensions might elide the personality dimensions}

\section{Could the problem be an underlying nonlinear structure?}

\section{Could the problem be the nonlinear transformation from cosine to Euclidean topology?}

\chapter{Future Work}

\section{Normalize vectors to unit length}

\todo{stub}

Since the cosine distance is the only one with direct semantic weight, I can 
get rid of noise that may be confusing PCA under the other transformations by
normalizing all score vectors to unit length. This leaves the cosine distance
unchanged but should make the Euclidean distance closer to the cosine distance
in those places where it diverges.

Why didn't I do it now? Because I would have had to reinterpret the dimensions.
(Though a dimension mapping from the already interpreted 2797-word list would
work.)

\section{Remove non-human words}

\todo{stub}

One of the dimensions in the 2797 word MDS analysis is a human-nonhuman 
dimension. It may measure to some extent the degree of polysemy of the words. A 
nice analysis would be to just extract the words that scored well on the human 
side of this scale and see what their most important dimensions are. It might 
reduce the noise significantly.

\section{Use directional statistics}

\todo{stub}

One problem with the MDS approach is that I can't standardize the range and 
mean beforehand because taking the z-scores of the dimensions changes the 
angles involved in the dot-products. However, I can map the word vectors to 
the unit sphere without changing the cosine distances. Then directional 
statistics give me analogous measures to the mean and standard deviation. 
Applying MDS to the distances in these standardized points should give me 
something much closer to the factor analysis normally used in psychology.

\todo{If I finish all sections but the discussion, I can try using directional 
stats to normalize the vectors before applying MDS}

\section{Rerun on other corpora or different random subsets of the same corpus}

\todo{Those factors that are stable can be assumed to be represent actual characteristics of language in general and not noise fitted by the algorithm in the particular corpus}

\subsection{Gigaword}
\subsection{Project Gutenberg}
\subsection{Smaller corpora}
\subsection{Small corpus from large starting point}

\section{Examine technique for detecting word usage shift between corpora}

\todo{Turn text summary of method below into more final version for future work}
Train model 1 on corpus 1. Save model 1. Train model 2 on corpus 2 using model 1 as a starting point. Align the two models (using words common to the two corpora and a loss function that depends on how many different words you expect (for example, if you will use $L^p$ norms\footnote{An $L^p$ norm calculates the length of an n-dimensional vector $x$ as $\|x\|_p=\left(|x_1|^p+|x_2|^p+\dotsb+|x_n|^p\right)^{\frac{1}{p}}$} and subtraction to calculate distance, you can use a lower $p$ exponent for a lower proportion of expected differences).

\section{Perform modeling in Euclidean topology}

\todo{Turn summary into final form}
Because the vectors must be converted to use Euclidean distances before PCA will work correctly, the principal components are not components of the vectors in cosine distance space. Thus, I can only rank the personality words and it is impossible to look for dimensions whose meaning will not be obvious based on ranking the personality words.

One approach would be to transform all the words. However the distance matrix alone would be enormous (5 hundred thousand words would require 250 billion distances). Since most modern MDS implementations use some form of gradient descent under the hood, I considered using stochastic gradient descent with the distance matrix being implicit in the original point values. The initial point for the descent could be the original point values since Euclidean and cosine distances are similar. However, that is a very special-purpose application of MDS. Since it could be hard to code due to the sizes of the data involved, and would only give an approximation of the best point locations, I don't think it is worth the effort at this time.

I think it is better to rewrite the training section of the skip-gram to use Euclidean rather than cosine distance. This modification will increase training time by a constant factor, but I would hope that factor is small.

\section{Do the big-5 etc. personality dimensions come out of a pseudo-personality test?}
\todo{Turn summary into final form}
What I mean is if you count the frequency for which different personality adjectives are used to describe different named person-entities in the corpus, do you get the same descriptive dimensions as you do for when you ask people to rate others on n dimensions.

\section{What happens if you tag personality words when they are referring to a specific person?}

\section{Use perplexity to calculate the number of personality dimensions}

\section{Use varimax rotation}

\todo{turn summary into final form} 

This might or might not be worthwhile. On the one hand, maybe the way
psychologists do it will produce the same result. On the other hand,
Goldberg \todo{cite ref goldberg 1990 An alternative ``Description of
  Personality''} found the same 5 factors using both common factor
analysis and principal components and both orthogonal and oblique
rotation.

\end{document}
