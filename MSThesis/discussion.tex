\documentclass[eric_thesis.tex]{subfiles}
\begin{document}
\chapter{Discussion}

\section{Interpretation of the dimensions}

As I performed the component extractions, I examined the sorted word-lists, 
which meant that I saw them in approximate numerical order according to the size 
of the list. As I examined the components for the smaller word lists, I had 
trouble coming up with coherent explanations. Some of the first few components 
seemed related to a good/bad trait listing but the rest of the components will 
be difficult to figure out. For example, components 1 and 2 of the unnormalized 
101 word set seem to be more-or-less good/bad. This is a rough characterization. 
Component 1 includes both extroverted and bashful on the ``bad'' side and 
component 2 includes prompt on its bad side. But the rest of the components are 
hard to describe. Even in the smaller lists, the MDS transform makes them much 
more interpretable. In the first two components, there are many fewer strange 
entries at the ends than when using the other two normalization methods. The 
rest of the components are still hard to interpret though this is more from a 
lack of vocabulary than from no sense in the ordering. In hindsight, having seen 
the larger MDS set, it is clear that the third component is sorted on formality 
and the fourth is related to how often the word is used to describe nonhuman 
versus human characteristics. 

\subsection{2797 Word with MDS}

Once I reached the 2797 word list based on \citep{Norman1967}, interpretation 
became much easier. I think more than 14 components might be interpretable, 
however, I only had time for 14. Several of those need some improvement. 
My interpretations are in Table
\ref{tab:2797mdsinterp}.

\subsubsection{Component 1}

The first dimension needs a bit of explanation. In the corpus, the 10 highest 
ranked words appear in 526,515/117,296,559 sentences (0.4\%), the 10 lowest 
ranked words appear in only 5,871 (0.005\%). This is even more pronounced in the 
minutes of the European parliament where the highly ranked words appear in 
19,196/2,015,440 sentences (1\%) but the lowest ranked words appear in 14 
(0.0006\%) (And, in all of those sentences, the only word appearing is 
sly\_jj - the highest ranked word among the lowest 10). Thus, it may not be 
just that these words are more common, but that they are more common in 
political speech.

I looked at the Spearman correlation between number of occurrences of the words 
in the entire corpus and the values on the first dimension. It was 0.5739 
(which gives a p value of $1.9120 \times 10^{-163}$ against the null hypothesis 
that there is no relationship). There is no other component which is so 
strongly correlated with word frequency. However, the correlation is not 
perfect. For example, the most frequent word in the list has a rank of 204 when 
you look at its score on the first dimension.

To investigate the hypothesis that these words are not just more common but 
more common in political speech, I also looked at the correlation with 
frequency in the European parliament records. The correlation goes up to 0.6881 
(p=3.8268e-261) and up to 0.7027 when looking at only words that appear in the 
parliamentary records. That it is not a perfect correlation indicates that 
there are still things I am overlooking. However, describing this dimension as 
``uncommon in parliament vs common'' seems to have some explanatory power.

\begin{table}[tbp]
\begin{tabular}{ | l |p{2in}|p{2in}|}
 \hline
 C & Low & High \\
 \hline
 1 & Uncommon in parliament & Common in parliament\\
 2 & Negative & Positive\\
 3 & Mainly describes humans & Describes non-humans also \\
 4 & Informal & Formal \\
 5 & Used in conflict & Used in peace \\
 6 & Unrelated to patriotism or authority-group loyalty & Related to 
     patriotism or authority-group loyalty \\
 7 & Stereotypical rebellious intellectual & Stereotypical opponent of 
     rebellious intellectual \\
 8 & Less emotional words & Emotionally charged words \\
 9 & Social / ostentation & Private  \\
 10 & Business context & Religion / family / clan context \\
 11 & Qualities relevant to violent situations & Qualities relevant to 
       non-violent situations \\
 12 & Unsettled exploration & Restaurant and food \\
 13 & Travel words & Interview words \\
 14 & Words that can describe both food and politicians &  Unknown \\
 \hline
\end{tabular}
 \caption{Interpretations of the different components identified from the 2797
 word list after MDS}
 \label{tab:2797mdsinterp}
\end{table}

\subsection{All combined with MDS}

Here the categories look similar to the 2797 word list. 

\begin{enumerate}
 \item Same
 \item Same
 \item Same
 \item Same
 \item Reversed from 2797
 \item Unknown
 \item Words that describe statements and people who make them thereby 
       affecting our interpretation thereof vs unknown
\end{enumerate}

\subsection{2797 with z-score}

These were much harder to interpret and there are more exceptions to each rule. 
This is to be expected from the difference between the dot-product space in 
which the similarity actually is measured and the euclidean space in which the 
z-score and PCA combination operates.

\begin{enumerate}
 \item business (low) \ldots fashion (high)
 \item socially pleasant (low) \ldots socially unpleasant (high) - mostly 
adjectives at the extremes.
 \item leadership qualities (low) vs ?words used in other contexts (words with 
less focus on personality)?
 \item things involving commitment/loyalty/disloyalty vs words that can 
describe art - but against this: ``lucky'' having to do with personality?
\end{enumerate}

\section{Thoughts on interpretations}

It seems that a lot of the dimensions are characteristics of the words 
themselves and not as much characteristics of what the word describes.

MDS is easier to interpret.




\section{Not what I expected}

\section{Could it be the corpus?}

WMT11 is a news corpus. Possibly its topic matter does not focus on people enough for those word senses to be properly represented. There are other, smaller, corpora with much broader language representation - for example, the brown corpus is a well known and freely available million word corpus. The British National Corpus is in the hundreds of millions of words and was created to be very broad-based. Additionally, there are spoken-language corpora like MICASE (Michigan Corpus of Academic Spoken English) and CPSA (Corpus of Spoken Professional American-English). These corpora could be used by themselves or potentially improved by using a model derived from a large news corpus like WMT11 or Gigaword as a starting point and then training on the smaller corpus.

\section{Could it be polysemy?}

\section{Could the dimensions be non-personality attributes?}
\section{Could the dimensions not be scaled on personality-ness?}

\todo{What I mean here is that the dimensions could be things like ``suitability to describe warmth'' both cold and warm would score highly but organized would score low.}

\section{Could the number of dimensions in the lexical model be affecting things?}

\section{Could the personality meanings not be being captured?}

\todo{This may be part of the previous - too few or too many dimensions might elide the personality dimensions}

\section{Could the problem be an underlying nonlinear structure?}

\section{Could the problem be the nonlinear transformation from cosine to Euclidean topology?}

\chapter{Future Work}

\section{Normalize vectors to unit length}

\todo{stub}

Since the cosine distance is the only one with direct semantic weight, I can 
get rid of noise that may be confusing PCA under the other transformations by
normalizing all score vectors to unit length. This leaves the cosine distance
unchanged but should make the Euclidean distance closer to the cosine distance
in those places where it diverges.

Why didn't I do it now? Because I would have had to reinterpret the dimensions.
(Though a dimension mapping from the already interpreted 2797-word list would
work.)

\section{Remove non-human words}

\todo{stub}

One of the dimensions in the 2797 word MDS analysis is a human-nonhuman 
dimension. It may measure to some extent the degree of polysemy of the words. A 
nice analysis would be to just extract the words that scored well on the human 
side of this scale and see what their most important dimensions are. It might 
reduce the noise significantly.

\section{Use directional statistics}

\todo{stub}

One problem with the MDS approach is that I can't standardize the range and 
mean beforehand because taking the z-scores of the dimensions changes the 
angles involved in the dot-products. However, I can map the word vectors to 
the unit sphere without changing the cosine distances. Then directional 
statistics give me analogous measures to the mean and standard deviation. 
Applying MDS to the distances in these standardized points should give me 
something much closer to the factor analysis normally used in psychology.

\todo{If I finish all sections but the discussion, I can try using directional 
stats to normalize the vectors before applying MDS}

\section{Rerun on other corpora or different random subsets of the same corpus}

\todo{Those factors that are stable can be assumed to be represent actual characteristics of language in general and not noise fitted by the algorithm in the particular corpus}

\subsection{Gigaword}
\subsection{Project Gutenberg}
\subsection{Smaller corpora}
\subsection{Small corpus from large starting point}

\section{Examine technique for detecting word usage shift between corpora}

\todo{Turn text summary of method below into more final version for future work}
Train model 1 on corpus 1. Save model 1. Train model 2 on corpus 2 using model 1 as a starting point. Align the two models (using words common to the two corpora and a loss function that depends on how many different words you expect (for example, if you will use $L^p$ norms\footnote{An $L^p$ norm calculates the length of an n-dimensional vector $x$ as $\|x\|_p=\left(|x_1|^p+|x_2|^p+\dotsb+|x_n|^p\right)^{\frac{1}{p}}$} and subtraction to calculate distance, you can use a lower $p$ exponent for a lower proportion of expected differences).

\section{Perform modeling in Euclidean topology}

\todo{Turn summary into final form}
Because the vectors must be converted to use Euclidean distances before PCA will work correctly, the principal components are not components of the vectors in cosine distance space. Thus, I can only rank the personality words and it is impossible to look for dimensions whose meaning will not be obvious based on ranking the personality words.

One approach would be to transform all the words. However the distance matrix alone would be enormous (5 hundred thousand words would require 250 billion distances). Since most modern MDS implementations use some form of gradient descent under the hood, I considered using stochastic gradient descent with the distance matrix being implicit in the original point values. The initial point for the descent could be the original point values since Euclidean and cosine distances are similar. However, that is a very special-purpose application of MDS. Since it could be hard to code due to the sizes of the data involved, and would only give an approximation of the best point locations, I don't think it is worth the effort at this time.

I think it is better to rewrite the training section of the skip-gram to use Euclidean rather than cosine distance. This modification will increase training time by a constant factor, but I would hope that factor is small.

\section{Do the big-5 etc. personality dimensions come out of a pseudo-personality test?}
\todo{Turn summary into final form}
What I mean is if you count the frequency for which different personality adjectives are used to describe different named person-entities in the corpus, do you get the same descriptive dimensions as you do for when you ask people to rate others on n dimensions.

\section{What happens if you tag personality words when they are referring to a specific person?}

\section{Use perplexity to calculate the number of personality dimensions}

\section{Use varimax rotation}

\todo{turn summary into final form} 

This might or might not be worthwhile. On the one hand, maybe the way
psychologists do it will produce the same result. On the other hand,
Goldberg \todo{cite ref goldberg 1990 An alternative ``Description of
  Personality''} found the same 5 factors using both common factor
analysis and principal components and both orthogonal and oblique
rotation.

\end{document}
